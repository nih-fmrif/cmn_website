{% extends "base.html" %}
{% load staticfiles %}
{% block title %}Machine Learning in Brain Imaging Series | CMN{% endblock %}
{% block content %}
	<div class=body>
		<h2>Machine Learning in Brain Imaging Series</h2>
		<p>The <strong>Machine Learning in Brian Imaging Series</strong> is a talk series sponsored by the NIMH that takes place every month on NIH main campus in Bethesda, MD. Invited speakers work at the intersection of neuroscience and machine learning. They come to the NIH for one or two days to present their research at the Talk Series, but also to meet with NIH researchers with shared interests. Talks include discussions on new machine learning methods as well as applications of machine learning to neuroscience research. Previous speakers in the series include: Dr. Tulay Adali (University of Maryland), Dr. Joshua Vogelstein (John Hopkins University), Dr. Christopher Honey (John Hopkins University), Dr. Vernon Lawhern (Army Research Lab), <a href=#spkr-jonas-richiardi>Dr. Jonas Richiardi (Lausane University Hospital)</a>, <a href=#spkr-gael-varoquaux>Gaël Varoquaux (INRIA)</a> and <a href=#spkr-yoshua-benigo>Dr. Yoshua Bengio (University of Montreal)</a>. The events pages contains <a href=/workshops>recordings of some of these talks</a>.</p>
		<p>All announcements are distributed via the <strong>MachineLearning-BrainImaging</strong> NIH e-mail list. If you want to join the list, or want to provide suggestions for future speakers, please contact <a href=mailto:javier.gonzalez-castillo@nih.gov>Javier Gonzalez-Castillo</a> or <a href=mailto:francisco.pereira@nih.gov>Francisco Pereira</a>.</p>
		<section aria-label="Previous Speakers" class=mlbis-previous-speakers>
			<article id=spkr-yoshua-benigo aria-labelledby=spkr-yoshua-benigo-hdr>
				<h3 id=spkr-yoshua-benigo-hdr>Yoshua Bengio</h3>
				<article id=talk-jan-2018-ai-deep-learning aria-labeled-by=talk-jan-2018-ai-deep-learning-hdr>
					<h4 id=talk-jan-2018-ai-deep-learning-hdr>AI and Deep Learning</h4>
					<p><a href={% static "videos/yoshua-bengio-ai-and-deep-learning.mp4" %}>Video</a></p>
					<h5 id=talk-jan-2018-ai-deep-learning-abstract>Abstract</h5>
					<p>Deep learning has arisen around 2006 as a renewal of neural networks research allowing such models to have more layers. It is leading the charge of a renewal of AI both inside and outside academia, with billions of dollars being invested and expected fallouts in the trillions by 2030. Theoretical investigations have shown that functions obtained as deep compositions of simpler functions (which includes both deep and recurrent nets) can express highly varying functions (with many ups and downs and different input regions that can be distinguished) much more efficiently (with fewer parameters) than otherwise. Empirical work in a variety of applications has demonstrated that, when well trained, such deep architectures can be highly successful, remarkably breaking through previous state-of-the-art in many areas, including speech recognition, object recognition, playing games, language models, machine translation and transfer learning. In terms of social impact, the most interesting applications probably are in the medical domain, starting with medical image analysis but expanding to many other areas. Finally, we summarize some of the recent work aimed at bridging the remaining gap between deep learning and neuroscience, including approaches to implement functional equivalents to backpropagation in a more biologically plausible way, as well as ongoing work connecting language, cognition, reinforcement learning and the learning of abstract representations.</p>
				</article>
				<h4>Biography</h4>
				<p>Yoshua Bengio (computer science, 1991, McGill U; post-docs at MIT and Bell Labs, computer science professor at U. Montréal since 1993), he authored three books, over 300 publications (h-index over 100), mostly in deep learning, holds a Canada Research Chair in Statistical Learning Algorithms, is Officer of the Order of Canada, recipient of the Marie-Victorin Quebec Prize 2017, he is a CIFAR Senior Fellow and co-directs its Learning in Machines and Brains program. He heads the Montreal Institute for Learning Algorithms (MILA), currently the largest academic research group on deep learning. On the NIPS foundation board (previously program chair and general chair), he co-created the ICLR conference. His goal is to uncover the principles of intelligence centered on learning, as well as contribute to the development of AI for the benefit of all.</p>
			</article>
			<article id=spkr-chris-baker aria-labelledby=spkr-chris-baker-hdr>
				<h3 id=spkr-chris-baker-hdr>Chris Baker</h3>
				<article id=talk-dec-2017-deep-nn-human-brain aria-labelledby=talk-dec-2017-deep-nn-human-brain-hdr>
					<h4 id=talk-dec-2017-deep-nn-human-brain-hdr>What can deep neural networks tell us about human brain and behavior?</h4>
					<p><a href={% static "videos/chris-baker-what-can-deep-neural-networks-tell-us-about-human-brain-and-behavior-20171211-1856-1.mp4" %}>Video</a></p>
					<h5 id=talk-dec-2017-deep-nn-human-brain-abstract>Abstract</h5>
					<p>Deep neural networks can now achieve human-like levels of performance on tasks such as visual categorization, and are increasingly being viewed as a viable computational model for brain function. In this talk I will present recent work from my lab comparing deep neural networks with both behavioral and neuroimaging experiments (fMRI and MEG) investigating object and scene perception. While deep neural networks show a correspondence with both neuroimaging and behavioral data, our results reveal a complex relationship between the three domains. Given our findings, a key question is how can we move beyond establishing mere correspondences between models and brain data towards generating truly novel insight into the sensory representations underlying adaptive behavior.</p>
				</article>
				<h4>Biography</h4>
				<p>Chris Baker is Chief of the Section on Learning and Plasticity in the Laboratory of Brain and Cognition at NIMH. He received his PhD from the University of St. Andrews in Scotland (working with Dave Perrett) before conducting postdoctoral studies at Carnegie Mellon University (working with Carl Olson and Marlene Behrmann) and MIT (working with Nancy Kanwisher). One major research focus is on understanding how high-level visual information is represented in the brain, and how such representations are modified by experience. His lab uses multidisciplinary approaches to tackle these questions including neuroimaging (fMRI, MEG), brain stimulation (TMS) and behavioral approaches.</p>
			</article>
			<article id=spkr-jonas-richiardi aria-labelledby=spkr-jonas-richiardi-hdr>
				<h3 id=spkr-jonas-richiardi-hdr>Jonas Richiardi</h3>
				<article id=talk-nov-2017-graph-infer-predict-neuroimaging aria-labelledby=talk-nov-2017-graph-infer-predict-neuroimaging-hdr>
					<h4 id=talk-nov-2017-graph-infer-predict-neuroimaging-hdr>Graph-based inference and prediction for neuroimaging</h4>
					<p><a href={% static "videos/jonas-richiardi-graph-based-inference-and-prediction-for-neuroimaging-20171127-1919-1.mp4" %}>Video</a></p>
					<h5 id=talk-nov-2017-graph-infer-predict-neuroimaging-abstract>Abstract</h5>
					<p>A network view of the brain has become ubiquitous in neuroscience. This has shifted focus from individual brain regions to macro-scale constructs including segregation and integration between remote regions. Complementing advances in multimodal non-invasive human imaging and signal processing, the mathematical tools that have allowed this perspective to flourish are graph theory and network science. By offering a constrained, yet expressive representation of large-scale, complex spatio-temporal data, graph approaches have enabled numerous systems-level insights into brain organization in health and disease. This talk will present mathematical tools that can be used to make sense of graph-structured brain data, both for group inference (graph-based statistics) and individual prediction (machine learning on brain graphs). We will particularly focus on applications in basic and clinical neuroscience, and show that graph-based approaches are particularly promising for inference across different levels and scales of brain biology.</p>
				</article>
				<h4>Biography</h4>
				<p>Jonas Richiardi is Clinical Research Lead at the Department of Radiology, Lausanne University Hospital, Switzerland, with joint appointment at Siemens Healthineers Advanced Clinical Imaging Technology. He was previously a Marie Curie fellow at Stanford University (working with Mike Greicius in Neurology) and the University of Geneva (working with Patrik Vuilleumier in Fundamental Neurosciences), and a post-doctoral researcher in the Medical Image Processing Lab, a joint position between the Ecole Polytechnique Fédérale de Lausanne (EPFL), Institute of Bioengineering, and the University of Geneva's Department of Radiology and Medical Informatics. He obtained his Ph.D. in signal processing and pattern recognition in 2007 at EPFL in the Signal Processing Institute. His research interests include modelling and inference for complex multimodal biological data, in particular functional magnetic resonance imaging data and its combination with genomic data. He is working on graph-based statistical learning approaches, where all data is first represented as a graph, and machine learning approaches are applied to form prediction with graphs. Applications are early diagnosis and prognosis for individual subjects, for diseases from Alzheimer disease to multiple sclerosis and schizophrenia. A recent effort is to develop these techniques so that they can be applied to messy, hospital-scale data.</p>
			</article>
			<article id=spkr-gael-varoquaux aria-labelledby=spkr-gael-varoquaux-hdr>
				<h3 id=spkr-gael-varoquaux-hdr>Gaël Varoquaux</h3>
				<article id=talk-oct-2017-big-data-rest-fmri aria-labelledby=talk-oct-2017-big-data-rest-fmri-hdr>
					<h4 id=talk-oct-2017-big-data-rest-fmri-hdr>Population imaging with resting-state fMRI: towards a big-data approach to psychiatry and psychology</h4>
					<p><a href={% static "videos/g-varoquaux-population-imaging-with-resting-state-fmri-towards-a-big-data-approach-to-psychiatry-and-psycho-20171017-1754-1.mp4" %}>Video</a></p>
					<h5 id=talk-oct-2017-big-data-rest-fmri-abstract>Abstract</h5>
					<p>Psychiatry and psychology are based on assessing individuals' traits, relying vastly on behavioral testing and questionnaires. Imaging of brain activity raises the hope of measuring the biological differences that underlie these psychological variations. In the long run, imaging could not only reveal mechanisms, but also help refine the definition of relevant traits and diseases. However, imaging-based research faces multiple challenges: How to measure function in pathologies? How to relate experiments? Can understanding arise from data?</p>
					<p>In this lecture, I will present one approach: massive data analysis on accumulation of rest fMRI across individuals. Rest fMRI is a good candidate for a universal marker of brain function, as it can easily be acquired on many different individuals. It reveals brain functional connectivity via "connectomes". The challenge is then to relate it to behavior and pathology. For this, we have developed a predictive-modeling pipeline; it successively defines regions from rest fMRI, build connectomes on these, and compares them across subjects using machine learning. My lecture will give the central ideas of such predictive connectomics, but also explore the new methodologies it opens for psychology and psychiatry.</p>
					<p>Machine learning extracts from the connectomes the specific information relevant to predict a given clinical diagnosis or psychological score. However, it requires large cohorts which may lead to heterogeneity with uncontrolled confounds. Studying a multi-site autism cohort, we have shown that aggregating across site was beneficial even for a ill-define spectrum disorder such as autism.</p>
					<p>Rest-fMRI may be combined with other modalities, that capture complementary information. For instance, brain aging induces specific changes in cortical thickness. I will show how such information can be merged in a predictive modeling approach to functional connectivity and lead to more accurate and more robust prediction.</p>
					<p>Individuals are characterized by multiple clinical and behavioral information, including age, diagnostic status, a variety of psychological assessments. I will show how predicting these jointly leads to a better description of the individuals, including an improvement in diagnostic accuracy.</p>
					<p>I will conclude with reflections on how these methodological developments, and those yet to come, can help shaping neuroimaging-based psychology and psychiatry. They face the challenge of the need for large cohorts, difficult to acquire and to control. Hence, they are complementary to focused study. Articulating wisely both approaches is a promising road to brain mechanisms.</p>
				</article>
			</article>
		</section>
	</div>
{% endblock content %}
